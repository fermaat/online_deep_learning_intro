{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating text with Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Reading\n",
    "Load the file from the data folder and inspect it. Standardize to lowercase. How long is the corpus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/home/fer/data/formaciones/master/deep-learning-intro/datasets/musquetaires/musquetairesShort\"\n",
    "raw_text = open(filename).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AUTHOR’S PREFACE\\n\\n\\nIn which it is proved that, notwithstanding their names’ ending in OS\\nand IS, the'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 198059\n"
     ]
    }
   ],
   "source": [
    "text = raw_text.lower()\n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text preparation\n",
    "We create a set with the different characters and two dictionaries from indices to chars\n",
    "<font color=red><b>Generate dictionaries for the char to indices and indices to chars.\n",
    "<br>_Hint: use the enumerate function on the chars set_</b>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 52\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we generate the input and output arrays:\n",
    "\n",
    "The input will consist on sentences of a fixed (_maxlen_) lenght, while the outputs will be the next characters in the text.\n",
    "\n",
    "So, if the text is \"Welcome to Big Data Spain\" with _maxlen_ = 5, we will have:\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Input = [\n",
    "     w, e, l, c, o,\n",
    "     e, l, c, o, m,\n",
    "     l, c, o, m, e,\n",
    "     ...\n",
    "    ]\n",
    "\n",
    "Output = [\n",
    "    m,\n",
    "    e, \n",
    "     ,\n",
    "     ...\n",
    "     ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to avoid overfitting (and improve performances) we can add a _step_ to the structure so that with step = 3, for example:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Input = [\n",
    "     w, e, l, c, o,\n",
    "     c, o, m, e,  , \n",
    "     m, e,  , t, o, \n",
    "     ...\n",
    "    ]\n",
    "\n",
    "Output = [\n",
    "    m,\n",
    "    t, \n",
    "     ,\n",
    "     ...\n",
    "     ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><b>Fill the sentences and next_char lists with the input and output data</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 66007\n"
     ]
    }
   ],
   "source": [
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['author’s preface\\n\\n\\nin which it is proved',\n",
       " 'hor’s preface\\n\\n\\nin which it is proved th',\n",
       " '’s preface\\n\\n\\nin which it is proved that,',\n",
       " 'preface\\n\\n\\nin which it is proved that, no',\n",
       " 'face\\n\\n\\nin which it is proved that, notwi']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ', 'a', ' ', 't', 't']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_chars[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset generation\n",
    "We turn the text into one-hot-like vectors. Initialize the Input and output arrays to zero as boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "Y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    Y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       ...,\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timesteps =  40 , numchars =  52\n"
     ]
    }
   ],
   "source": [
    "print (\"timesteps = \", len (X[0]), \", numchars = \", len (X[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Generation\n",
    "Build the LSTM model to be trained train on the data, on this config:\n",
    "- LSTM layer, with 256 units\n",
    "- LSTM layer, with 256 units\n",
    "- Dense layer, with 64 units\n",
    "- Dense softmax layer\n",
    "- On compilation, use adam as the optimizer and categorical_crossentropy as the loss function.\n",
    "- Print the summary\n",
    "\n",
    "\n",
    "<font color=red><b>Remember to initialize it propperly and to include input_shape on the first layer. <br> Hints: input_shape= (maxlen, len(chars))\n",
    "- Use the imported libraries</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "tf.keras.backend.clear_session() \n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 40, 256)           316416    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 52)                3380      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 52)                0         \n",
      "=================================================================\n",
      "Total params: 861,556\n",
      "Trainable params: 861,556\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(maxlen, len(chars)), return_sequences=True))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dense(64))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "Train the model for a couple of epochs and see how it works. Use a batch_size of 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 66007 samples\n",
      "Epoch 1/2\n",
      "66007/66007 [==============================] - 14s 215us/sample - loss: 2.6595\n",
      "Epoch 2/2\n",
      "66007/66007 [==============================] - 11s 172us/sample - loss: 2.0999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff8504bcc50>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y,\n",
    "      batch_size=128,\n",
    "      epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "Let's test our model. In order to obtain a probabilistic answer we can sample from a probability array instead of just taking the max argument:\n",
    "\n",
    "<font color=red><b> Sometimes probabilities are rounded. Apply a normalization-like tratment to them in order to avoid this when sampling</b> </font>\n",
    "\n",
    "\n",
    "$$ p_i = \\frac{p_i}{\\sum_j p_j}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, sample = True):\n",
    "    if sample:\n",
    "        # probs can be rounded and not sum up to one. We recalculate in order to avoid this\n",
    "        preds = np.asarray(preds).astype('float64')\n",
    "        preds = preds /np.sum (preds)\n",
    "        probas = np.random.multinomial(1, preds, 1)\n",
    "    else:\n",
    "        probas = preds\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a seed in order to predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of ten years of his existence. but m. de\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "generated = ''\n",
    "sentence = text[start_index: start_index + maxlen]\n",
    "generated += sentence\n",
    "print (generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions\n",
    "This will be the secuence for which we are going to predict the next character:\n",
    "\n",
    "<font color=red> <b> Predict the next character given the input x_pred. <br>Hint: remember to take the first item in list</b>  </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predict next character given a model and the sequence to predict \n",
    "def get_next_char (model, x_pred, indices_char, Sample = True):\n",
    "    preds = model.predict(x_pred, verbose=0)[0]\n",
    "    next_index = sample(preds, 1.0)\n",
    "    return indices_char[next_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    }
   ],
   "source": [
    "x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "for t, char in enumerate(sentence):\n",
    "    x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "Sample = True\n",
    "    \n",
    "next_char = get_next_char (model, x_pred, indices_char, Sample)  \n",
    "\n",
    "print (next_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's predict some more characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: hat he returned too\n",
      "late to present hims\"\n",
      "---------------------- Generated Text -----------------------\n",
      "tever, whal to swor “fotem, sobe, ifunletebun uc\n",
      "sint muskete, and ho wo duplet, se d’aytugan and whe\n",
      "whored\n",
      "ard.\n",
      "“blatrey b( to yout, at co i. dag, dut the elwacis him. shat whomet to to mose contery the must that he half llalisidled you sorst who has, of whac\n",
      "wiby his his pastecontoluct; well\n",
      "fathet buthers aid ouvely burle dus queateurt, the dut\n",
      "buthifulither to\n",
      "cu to dparny my mas; if, ad whit"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "sentence = text[start_index: start_index + maxlen]\n",
    "print('Seed: ' + sentence + '\"')\n",
    "print('---------------------- Generated Text -----------------------')\n",
    "# sys.stdout.write(generated)\n",
    "for i in range(400):\n",
    "    x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "    for t, char in enumerate(sentence):\n",
    "        x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "    next_char = get_next_char (model, x_pred, indices_char, Sample)\n",
    "    sentence = sentence[1:] + next_char\n",
    "\n",
    "    sys.stdout.write(next_char)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a trained model\n",
    "Training Deep Learning Models is time consuming. So, some pretrained models are available to be loaded and take a look at better predictions. We will load a model for each 5 epochs in order to see the evolution. \n",
    "\n",
    "<font color=red> <b> Load a model for each time and predict the text <br> Hint: You can load the whole model or just the weights as the configuration is the same</b>  </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------- Next Model --------------\n",
      "Trained on  5  epochs\n",
      "Seed: he manner in which d’artagnan had left h\"\n",
      "---------------------- Generated Text -----------------------\n",
      "im. he and whom d’artagnan was speaking as could not be\n",
      "bore coused.\n",
      "\n",
      "bonacieux, presented his eyes to us? noo, i know now you will jumes you-low ma!” rellied athos.\n",
      "\n",
      "“no, i know it cannot in enembgate with with me.\n",
      "\n",
      "“\"bonacieux,” said urly; “monsieur, i deam- prudence’s majesty passion, mad, who for milady crink\n",
      "with him, and full himself, hed the door the single of a king of time on the king out\n",
      "-------------- Next Model --------------\n",
      "Trained on  10  epochs\n",
      "Seed: nued d’artagnan, with natural\n",
      "assurance;\"\n",
      "---------------------- Generated Text -----------------------\n",
      " by that athos placed busing themselves without secrets.\n",
      "the queen uncovered in a horse expected would have heard a new pursue the narches of st. vaitue, which was turned\n",
      "a sign diy taken paraped a greatly respectly to soldiers.\n",
      "\n",
      "at presish, the sman of arage. that’s turned mousqueton the bassion, and tried of the wager of the route herself gives me open.”\n",
      "\n",
      "“gave me your godd man, while you loved \n",
      "-------------- Next Model --------------\n",
      "Trained on  15  epochs\n",
      "Seed: that disturbs you?”\n",
      "\n",
      "“by no means.”\n",
      "\n",
      "“an\"\n",
      "---------------------- Generated Text -----------------------\n",
      "d i,” continued mme. bonacieux, considering the stranger, he was not finished\n",
      "with nobody of monsieur lap reparation is seriously, monsieur?” replied milady, his order for his eyes, course to\n",
      "understand her, he deviled it, and he necess\n",
      "expected are sticled, and on making a prison from the\n",
      "sight of the cardinal, for their men, one or three features which made his family successon. toward the globl\n",
      "-------------- Next Model --------------\n",
      "Trained on  20  epochs\n",
      "Seed: use i confide in that justice that i sha\"\n",
      "---------------------- Generated Text -----------------------\n",
      "ll no; but i saw you always\n",
      "reastered, envousions. this promise of m.\n",
      "\n",
      "chevilies would alroad him strangel the spores of magnifite himself. in a convect contain\n",
      "of none thirte--as ladies, and the affair of the horses,\n",
      "in all even became (on the left energh which baren toward the cardinal; and\n",
      "when he had been had no longer me that i sense that you want to have\n",
      "implaiced it me?”\n",
      "\n",
      "“no! cour to say, \n",
      "-------------- Next Model --------------\n",
      "Trained on  25  epochs\n",
      "Seed: it, but still it is the fashion. besides\"\n",
      "---------------------- Generated Text -----------------------\n",
      ", a little misseuber will hundred mestress.”\n",
      "\n",
      "“to think i do’t oply.”\n",
      "\n",
      "“yes,” cried d’artagnan, with an anjou\n",
      "toile. now these fathers, you make me.”\n",
      "\n",
      "the king and the man forced to obeyond, but after him a real which he had been all enough to folly the\n",
      "name and of which i enter to assist me! and i have pure\n",
      "out of a shade of the crocularions of earthip. you crose to me the\n",
      "ruices of your majesty.\n",
      "-------------- Next Model --------------\n",
      "Trained on  30  epochs\n",
      "Seed: yourselves.”\n",
      "\n",
      "“gentlemen,” said jussac, \"\n",
      "---------------------- Generated Text -----------------------\n",
      "as it is sent and the bast to meet age him. i passed to him and drew a gentleman.”\n",
      "\n",
      "he had theors returned; the king was always to detain the strueg and sleep, and he perceived they only together, and the little trouble she is now, and let us to be still to the louvre of\n",
      "an increfies.”\n",
      "\n",
      "d’artagnan eased him into the passion over the hotel desire, to\n",
      "whom that it was already of his letters.\n",
      "\n",
      "they h\n",
      "-------------- Next Model --------------\n",
      "Trained on  35  epochs\n",
      "Seed: inconvenient.”\n",
      "\n",
      "“very inconvenient, upon\"\n",
      "---------------------- Generated Text -----------------------\n",
      " me?”\n",
      "\n",
      "“see it orrer.”\n",
      "\n",
      "the officer required, and formid d’artagnan. he took the leader of the bastion,\n",
      "the best ready case up any intrigues, porthos and aramis resumed their\n",
      "proude. the host that one was weiling into terrible thought had been all her unfortunate effrending from any heart--a vasy\n",
      "that every servant, the young man of monsieur de\n",
      "treville, and this woman how he was right. he\n",
      "left an\n",
      "-------------- Next Model --------------\n",
      "Trained on  40  epochs\n",
      "Seed: or, and who had the honor to be, as a ch\"\n",
      "---------------------- Generated Text -----------------------\n",
      "ild, the musketeers\n",
      "rejeined the courtesal gate of the blide, and leave ut killed by\n",
      "this woman has he disappeared.\n",
      "\n",
      "\n",
      "\n",
      "2’artagnan read the cardinal that continuies to\n",
      "kissed the cardinal, who was preserved.\n",
      "\n",
      "milady remained in a convisiation which had received four.”\n",
      "\n",
      "“the very puritan of hand, monsieur; but as the courty\n",
      "and perhaps the louds of the study, green use. the manstrized her chamber, e\n",
      "-------------- Next Model --------------\n",
      "Trained on  45  epochs\n",
      "Seed: d of the reign of king louis\n",
      "xiii and th\"\n",
      "---------------------- Generated Text -----------------------\n",
      "e stranger, and perceived that they\n",
      "did not live to his letter in the rest, more she had thrown the posts of war age of the street which athos alone\n",
      "shall satdlechies fain.nd on the first ide-indocred--and the glass of the enemy of milady,\n",
      "silence, had lost me, and i am found a hundred pistoles for your delicate. seir now, with your pocket that has had the bottoatue of the\n",
      "presence of a man who ha\n",
      "-------------- Next Model --------------\n",
      "Trained on  50  epochs\n",
      "Seed: ng to the lady, he sprang into\n",
      "his saddl\"\n",
      "---------------------- Generated Text -----------------------\n",
      "e, saddled of bars.\n",
      "\n",
      "d’artagnan was already sprang toward her.\n",
      "\n",
      "“and i have an erger mistress, and i am in officer from the lieutenant\n",
      "gate to the weet and travelers, but ear, alting\n",
      "his hand behind him, and he rapidled the king, grimaud had\n",
      "put all the door, which alady the greatest disting herself\n",
      "inclination to doubt, on the contrary, he began to\n",
      "exame lackey, something was every day, and i wil\n",
      "-------------- Next Model --------------\n",
      "Trained on  55  epochs\n",
      "Seed:  hunting\n",
      "in the forest of st. germain. m\"\n",
      "---------------------- Generated Text -----------------------\n",
      "ore the satisfied of the hotel of ten send you the window. you must be placed in the day. at is one if we railed this conduct an ester,\n",
      "like us of a man of two o’clock sink of by a dozen milady the sun, the idea was in a good man; but as needs he\n",
      "had not any disting their encalled eperishable\n",
      "powerful mais!ning the louds cartes, and we bow, in which the cardinal called in it, and he went only two \n",
      "-------------- Next Model --------------\n",
      "Trained on  60  epochs\n",
      "Seed: \n",
      "loudly than his pacific resolutions. “i\"\n",
      "---------------------- Generated Text -----------------------\n",
      " believe so; i may succeed in monsieur de business still driving out of the wound to submitted\n",
      "anything was a large cleak, and she retisted.\n",
      "\n",
      "as to felton, who feared word the room of the streaches in their hands of the cardinal.”\n",
      "\n",
      "“which have is delighted to sure you,” replied athos, “you shall know what the king’s musk\n",
      "understanding, but i wisted to think of honor; “i will no stinct. i\n",
      "have no f"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "partial_n_epoch = 5\n",
    "times = 12\n",
    "\n",
    "## Set both starts for the seed sentence and the multinomial prediction\n",
    "np.random.seed (2)\n",
    "for j in range (times):\n",
    "    \n",
    "    count += partial_n_epoch\n",
    "    print (\"\")\n",
    "    print (\"-------------- Next Model --------------\")\n",
    "    print (\"Trained on \", count, \" epochs\")\n",
    "    modelName = '/home/fer/data/formaciones/master/deep-learning-intro/models/musquetaires/MusquetairesModelOptimizedMode_' + str (count) + '.h5' \n",
    "\n",
    "    model.load_weights (modelName)\n",
    "   \n",
    "    start_index = np.random.randint(0, len(text) - maxlen - 1)\n",
    "    sentence = text[start_index: start_index + maxlen]\n",
    "    print('Seed: ' + sentence + '\"')\n",
    "    print('---------------------- Generated Text -----------------------')\n",
    "    # sys.stdout.write(generated)\n",
    "    for i in range(400):\n",
    "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "        next_char = get_next_char (model, x_pred, indices_char, Sample)\n",
    "        sentence = sentence[1:] + next_char\n",
    "\n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_tf2",
   "language": "python",
   "name": "dl_tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
