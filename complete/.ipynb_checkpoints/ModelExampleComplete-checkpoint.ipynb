{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model Basics\n",
    "In this Notebook we will learn how to build a Neural Network model, train it and evaluate its performance. We will build a model to be used on the Mnist dataset, which is composed of handwritten digits. The task is to classify each digit 0, 1, 2, ... 9.\n",
    "\n",
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "tf.keras.backend.clear_session() \n",
    "\n",
    "# Mnist data load\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HyperPrameter definition\n",
    "Standard hyperparameters to be used:\n",
    "- epochs: Number of times to iterate over the training data arrays.\n",
    "- batch_size: In gradient descent-like algorithms, this is the number of samples per gradient update. Can be set to 1 to online learning \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "# Image dimensions\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data reshape\n",
    "Mnist dataset consist in hadwritten digit images. So, each data istance is an image, composed of pixels (numbers from 0 to 255): \n",
    "\n",
    "<img src=\"../data/8-gif.gif\">\n",
    "\n",
    "Foe a general image, its dimensions are $rows\\times columns\\times channels$. In our case every image is greyscaled, but colored images can have more channels (3 on RGB)\n",
    "\n",
    "Images can be seen as tensors, and they have a TensorFlow standard format: $rows\\times columns\\times channels$, while, for example in Theano it is different ($channels \\times rows\\times columns$). Thus, in order to make use of images in such way, we have to reshape our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len (x_train), len (x_train[0]), len (x_train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add another dimension to the known $channels \\times rows\\times columns$: the number of instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "input_shape_extend =  (None, ) + input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Networks ussually perform better on scaled images. \n",
    "<font color=red><b>Scale the images </font>\n",
    "<br>We also need the target variable on the standard sci-kit one hot format.\n",
    "\n",
    "\n",
    "<br><font color=red><b> Transform the target variables to categorical one-hot encoding\n",
    "<br>Hint: use the function  keras.utils.to_categorical on the train and test targets </b>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# normalization\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "# scikit learn target standard style\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model construction\n",
    "\n",
    "We will use Keras to build Neural Net models in order to predict our target. We will cover two ways to build the models, which I named Sequential and Functorial:\n",
    "\n",
    "### 1.- Sequential style\n",
    "\n",
    "Layers are added sequentially, as modules. The Sequential model is a linear stack of layers:\n",
    "- First of all, we have to define the model as sequential:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Then we can add more layers, like this:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.add (LayerKind (layerparameters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>Remark:</b> for the first layer, one of the parameters must be the input or batch size. So, the first layer added can be something like this"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.add (LayerKind (layerparameters, input_shape = input_shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Then we can add more and more layers:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.add (LayerKind1 (layerparameters1))\n",
    "model.add (LayerKind2 (layerparameters2))\n",
    "model.add (LayerKind3 (layerparameters3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A common strategy on image models is to add some Fully connected layers at the end. Even it it is just one, images must be flattened so that predictions fit the required dimension. So, it is needed to add a Flatten() layer:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.add (Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Finally, the last layer must match the dimensions of our target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 1.1.- Model building\n",
    "\n",
    "\n",
    "<font color=red><b> Build a sequential-like model using this arquitecture:\n",
    "<br> - Dense layer with 24 units and a relu activation function <b> before the flattenning</b> Probably it has no sense to add a Dense layer to an image-like input. Instead a convolutional layer would probably be a lot better. \n",
    "<br> - Flattenning layer\n",
    "<br> - Dense layer with the output-expected units and a softmax activation function\n",
    "<br>Hint: use the imported layers </b>\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building model\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "model.add (Dense(24, activation='relu', input_shape = input_shape))\n",
    "model.add(Flatten())\n",
    "model.add (Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.- Compilation\n",
    "In order to work, the model has to be compiled. In compilation we add the optimizer on which the BackProp will be performed, and the loss function to be used. Additionally, we can add some metrics to control the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 28, 28, 24)        48        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 18816)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                188170    \n",
      "=================================================================\n",
      "Total params: 188,218\n",
      "Trainable params: 188,218\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.- Model Training\n",
    "Finally, the model can be trained. in order to validate the model performances, we can add our test sets to check the metrics on both training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.3978 - accuracy: 0.8911 - val_loss: 0.2835 - val_accuracy: 0.9218\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.2871 - accuracy: 0.9193 - val_loss: 0.2835 - val_accuracy: 0.9185\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.2748 - accuracy: 0.9233 - val_loss: 0.2780 - val_accuracy: 0.9231\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.2677 - accuracy: 0.9249 - val_loss: 0.2708 - val_accuracy: 0.9249\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.2628 - accuracy: 0.9258 - val_loss: 0.2717 - val_accuracy: 0.9239\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.2599 - accuracy: 0.9270 - val_loss: 0.2684 - val_accuracy: 0.9261\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.2575 - accuracy: 0.9286 - val_loss: 0.2803 - val_accuracy: 0.9231\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.2554 - accuracy: 0.9279 - val_loss: 0.2771 - val_accuracy: 0.9234\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.2539 - accuracy: 0.9290 - val_loss: 0.2754 - val_accuracy: 0.9253\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.2507 - accuracy: 0.9307 - val_loss: 0.2731 - val_accuracy: 0.9250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcc48b0e320>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.- Results check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.27311971493065357\n",
      "Test accuracy: 0.925\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.- Functorial style\n",
    "This style is called functorial because each layer can be seen as a functor applied to the previous one\n",
    "#### 2.1.- Model Architecture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First of all, we have to define the input. For our purposes, we will include the batch shape:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x = Input(batch_shape=input_shape_extend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Then the next layers can be added by applying them to the previous ones:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "h =LayerKind (layerparameters)(x)\n",
    "h1 =LayerKind1 (layerparameters1)(h)\n",
    "h2 =LayerKind2 (layerparameters2)(h1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Layers can be kept separated (we will make use of this on later demos) or renamed:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "h =LayerKind (layerparameters)(x)\n",
    "h =LayerKind1 (layerparameters1)(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As in the previous example, for images we can make use of the Flatten() layer and remember the last layer must match the dimensions of our target variable\n",
    "- Finally, we define the model, using the input and the final layer as parameters:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "...\n",
    "output = LayerKindn (layerparametersn)(previousLayer)\n",
    "model2 = Model(x, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><b> Build a model with the same architecture as the one on the sequential stile </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "#building model\n",
    "x = Input(batch_shape=input_shape_extend)\n",
    "h = Dense(24, activation='relu')(x)\n",
    "h2 = Flatten()(h)\n",
    "output = Dense(num_classes, activation='softmax')(h2)\n",
    "model2 = Model(x, output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.- Compilation\n",
    "<font color=red><b> Compile the previously built model. Print its summary </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 28, 28, 24)        48        \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18816)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                188170    \n",
      "=================================================================\n",
      "Total params: 188,218\n",
      "Trainable params: 188,218\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.- Model Training\n",
    "<font color=red><b> Train the previously built model </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.4360 - accuracy: 0.8834 - val_loss: 0.2893 - val_accuracy: 0.9178\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.2892 - accuracy: 0.9176 - val_loss: 0.2742 - val_accuracy: 0.9240\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.2746 - accuracy: 0.9234 - val_loss: 0.2681 - val_accuracy: 0.9243\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.2690 - accuracy: 0.9247 - val_loss: 0.2754 - val_accuracy: 0.9200\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.2628 - accuracy: 0.9265 - val_loss: 0.2728 - val_accuracy: 0.9246\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.2602 - accuracy: 0.9276 - val_loss: 0.2667 - val_accuracy: 0.9249\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.2564 - accuracy: 0.9297 - val_loss: 0.2774 - val_accuracy: 0.9217\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.2544 - accuracy: 0.9288 - val_loss: 0.2696 - val_accuracy: 0.9259\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.2518 - accuracy: 0.9296 - val_loss: 0.2718 - val_accuracy: 0.9271\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.2506 - accuracy: 0.9306 - val_loss: 0.2698 - val_accuracy: 0.9256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcbcc39a6d8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.- Results check\n",
    "<font color=red><b> Check the accuracy of model2 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.2697527746811509\n",
      "Test accuracy: 0.9256\n"
     ]
    }
   ],
   "source": [
    "score = model2.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error: 7.440000772476196 %\n"
     ]
    }
   ],
   "source": [
    "# state of the art: 0.21%\n",
    "print('Test error:', 100 * (1 - score[1]), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.- Model save and load\n",
    "As many DL models needs some time to be trained, it is usefull to be able to keep the weights or even the whole model\n",
    "#### Weights save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('../models/mnistconv.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save ('../models/modeloentero.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weight load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights ('../models/mnistconv.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "# whole model load\n",
    "model2 = load_model ('../models/modeloentero.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No model found in config file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-39520d507555>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# if it only has the weights, it fails\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# model3.load_weights ('mnistconv.h5')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'../models/mnistconv.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/data/venvs/dl_tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    144\u001b[0m   if (h5py is not None and (\n\u001b[1;32m    145\u001b[0m       isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mhdf5_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model_from_hdf5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/venvs/dl_tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_config'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel_config\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No model found in config file.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     model = model_config_lib.model_from_config(model_config,\n",
      "\u001b[0;31mValueError\u001b[0m: No model found in config file."
     ]
    }
   ],
   "source": [
    "# if it only has the weights, it fails\n",
    "# model3.load_weights ('mnistconv.h5')\n",
    "model3 = load_model ('../models/mnistconv.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
